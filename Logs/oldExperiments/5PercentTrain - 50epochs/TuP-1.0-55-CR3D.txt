2021-02-15 22:57:33.943280: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/lib64
2021-02-15 22:57:33.943395: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64:/usr/local/cuda-10.1/lib64
2021-02-15 22:57:33.943406: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2021-02-15 22:57:36.446572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-02-15 22:57:36.454224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:37:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s
2021-02-15 22:57:36.454450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-02-15 22:57:36.456748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-02-15 22:57:36.459086: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-02-15 22:57:36.459429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-02-15 22:57:36.461954: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-02-15 22:57:36.463220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-02-15 22:57:36.468310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-02-15 22:57:36.470208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2021-02-15 22:57:36.470604: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2021-02-15 22:57:36.483375: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2021-02-15 22:57:36.489323: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x686e400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-02-15 22:57:36.489352: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-02-15 22:57:36.644029: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x68d4ab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-02-15 22:57:36.644067: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-16GB, Compute Capability 7.0
2021-02-15 22:57:36.645776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:37:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0
coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s
2021-02-15 22:57:36.645860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-02-15 22:57:36.645891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-02-15 22:57:36.645917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-02-15 22:57:36.645942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-02-15 22:57:36.645967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-02-15 22:57:36.645994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-02-15 22:57:36.646019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-02-15 22:57:36.649167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2021-02-15 22:57:36.649235: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-02-15 22:57:36.652382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-02-15 22:57:36.652408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2021-02-15 22:57:36.652426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2021-02-15 22:57:36.655398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13761 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:37:00.0, compute capability: 7.0)
2021-02-15 22:57:39.402402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-02-15 22:57:39.752695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-02-15 22:57:00.882099
SNR= 55dB
Alpha= alpha-1.0
---The HSI selected is: paviaU ---
The shape of the image is: (610, 340, 103)
The shape of the labels is: (610, 340)
Number of classes:  9
Standard Scaler preprocessing method applied
The new dimensions for the compressed HSI is: (610, 340, 40) obtained by Tucker
The new shape of the data is:  (207400, 19, 19, 40)
The new shape of the labels is:  (207400,)
The data shape for train is: (2138, 19, 19, 40)
The labels shape for train is: (2138,)
The data shape for test is: (40638, 19, 19, 40)
The labels shape for test is: (40638,)
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_1 (Conv3D)            (None, 15, 15, 17, 32)    19232     
_________________________________________________________________
batch_normalization_1 (Batch (None, 15, 15, 17, 32)    128       
_________________________________________________________________
activation_1 (Activation)    (None, 15, 15, 17, 32)    0         
_________________________________________________________________
conv3d_2 (Conv3D)            (None, 11, 11, 2, 64)     819264    
_________________________________________________________________
batch_normalization_2 (Batch (None, 11, 11, 2, 64)     256       
_________________________________________________________________
activation_2 (Activation)    (None, 11, 11, 2, 64)     0         
_________________________________________________________________
max_pooling3d_1 (MaxPooling3 (None, 5, 5, 2, 64)       0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 3200)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 300)               960300    
_________________________________________________________________
batch_normalization_3 (Batch (None, 300)               1200      
_________________________________________________________________
activation_3 (Activation)    (None, 300)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 9)                 2709      
=================================================================
Total params: 1,803,089
Trainable params: 1,802,297
Non-trainable params: 792
_________________________________________________________________
Train on 2138 samples, validate on 40638 samples
Epoch 1/50

Epoch 00001: val_accuracy improved from -inf to 0.57559, saving model to /tmp/best_model.h5
Epoch 2/50

Epoch 00002: val_accuracy improved from 0.57559 to 0.92131, saving model to /tmp/best_model.h5
Epoch 3/50

Epoch 00003: val_accuracy improved from 0.92131 to 0.95032, saving model to /tmp/best_model.h5
Epoch 4/50

Epoch 00004: val_accuracy improved from 0.95032 to 0.95684, saving model to /tmp/best_model.h5
Epoch 5/50

Epoch 00005: val_accuracy improved from 0.95684 to 0.97714, saving model to /tmp/best_model.h5
Epoch 6/50

Epoch 00006: val_accuracy did not improve from 0.97714
Epoch 7/50

Epoch 00007: val_accuracy improved from 0.97714 to 0.97724, saving model to /tmp/best_model.h5
Epoch 8/50

Epoch 00008: val_accuracy did not improve from 0.97724
Epoch 9/50

Epoch 00009: val_accuracy did not improve from 0.97724
Epoch 10/50

Epoch 00010: val_accuracy did not improve from 0.97724
Epoch 11/50

Epoch 00011: val_accuracy did not improve from 0.97724
Epoch 12/50

Epoch 00012: val_accuracy did not improve from 0.97724
Epoch 13/50

Epoch 00013: val_accuracy did not improve from 0.97724
Epoch 14/50

Epoch 00014: val_accuracy did not improve from 0.97724
Epoch 15/50

Epoch 00015: val_accuracy did not improve from 0.97724
Epoch 16/50

Epoch 00016: val_accuracy improved from 0.97724 to 0.97756, saving model to /tmp/best_model.h5
Epoch 17/50

Epoch 00017: val_accuracy improved from 0.97756 to 0.97891, saving model to /tmp/best_model.h5
Epoch 18/50

Epoch 00018: val_accuracy improved from 0.97891 to 0.98364, saving model to /tmp/best_model.h5
Epoch 19/50

Epoch 00019: val_accuracy improved from 0.98364 to 0.98398, saving model to /tmp/best_model.h5
Epoch 20/50

Epoch 00020: val_accuracy improved from 0.98398 to 0.98637, saving model to /tmp/best_model.h5
Epoch 21/50

Epoch 00021: val_accuracy improved from 0.98637 to 0.98674, saving model to /tmp/best_model.h5
Epoch 22/50

Epoch 00022: val_accuracy improved from 0.98674 to 0.99102, saving model to /tmp/best_model.h5
Epoch 23/50

Epoch 00023: val_accuracy improved from 0.99102 to 0.99252, saving model to /tmp/best_model.h5
Epoch 24/50

Epoch 00024: val_accuracy improved from 0.99252 to 0.99299, saving model to /tmp/best_model.h5
Epoch 25/50

Epoch 00025: val_accuracy improved from 0.99299 to 0.99409, saving model to /tmp/best_model.h5
Epoch 26/50

Epoch 00026: val_accuracy improved from 0.99409 to 0.99481, saving model to /tmp/best_model.h5
Epoch 27/50

Epoch 00027: val_accuracy improved from 0.99481 to 0.99515, saving model to /tmp/best_model.h5
Epoch 28/50

Epoch 00028: val_accuracy improved from 0.99515 to 0.99552, saving model to /tmp/best_model.h5
Epoch 29/50

Epoch 00029: val_accuracy improved from 0.99552 to 0.99604, saving model to /tmp/best_model.h5
Epoch 30/50

Epoch 00030: val_accuracy improved from 0.99604 to 0.99683, saving model to /tmp/best_model.h5
Epoch 31/50

Epoch 00031: val_accuracy improved from 0.99683 to 0.99717, saving model to /tmp/best_model.h5
Epoch 32/50

Epoch 00032: val_accuracy improved from 0.99717 to 0.99734, saving model to /tmp/best_model.h5
Epoch 33/50

Epoch 00033: val_accuracy improved from 0.99734 to 0.99766, saving model to /tmp/best_model.h5
Epoch 34/50

Epoch 00034: val_accuracy improved from 0.99766 to 0.99786, saving model to /tmp/best_model.h5
Epoch 35/50

Epoch 00035: val_accuracy improved from 0.99786 to 0.99815, saving model to /tmp/best_model.h5
Epoch 36/50

Epoch 00036: val_accuracy improved from 0.99815 to 0.99823, saving model to /tmp/best_model.h5
Epoch 37/50

Epoch 00037: val_accuracy improved from 0.99823 to 0.99825, saving model to /tmp/best_model.h5
Epoch 38/50

Epoch 00038: val_accuracy improved from 0.99825 to 0.99830, saving model to /tmp/best_model.h5
Epoch 39/50

Epoch 00039: val_accuracy improved from 0.99830 to 0.99838, saving model to /tmp/best_model.h5
Epoch 40/50

Epoch 00040: val_accuracy improved from 0.99838 to 0.99860, saving model to /tmp/best_model.h5
Epoch 41/50

Epoch 00041: val_accuracy improved from 0.99860 to 0.99867, saving model to /tmp/best_model.h5
Epoch 42/50

Epoch 00042: val_accuracy did not improve from 0.99867
Epoch 43/50

Epoch 00043: val_accuracy improved from 0.99867 to 0.99870, saving model to /tmp/best_model.h5
Epoch 44/50

Epoch 00044: val_accuracy improved from 0.99870 to 0.99875, saving model to /tmp/best_model.h5
Epoch 45/50

Epoch 00045: val_accuracy did not improve from 0.99875
Epoch 46/50

Epoch 00046: val_accuracy improved from 0.99875 to 0.99877, saving model to /tmp/best_model.h5
Epoch 47/50

Epoch 00047: val_accuracy improved from 0.99877 to 0.99879, saving model to /tmp/best_model.h5
Epoch 48/50

Epoch 00048: val_accuracy did not improve from 0.99879
Epoch 49/50

Epoch 00049: val_accuracy improved from 0.99879 to 0.99884, saving model to /tmp/best_model.h5
Epoch 50/50

Epoch 00050: val_accuracy improved from 0.99884 to 0.99889, saving model to /tmp/best_model.h5
PARAMETERS 1803089

Terminado en 317.6004636287689 segundos!


Classification report:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      6299
           1       1.00      1.00      1.00     17717
           2       1.00      1.00      1.00      1994
           3       1.00      0.99      0.99      2911
           4       1.00      1.00      1.00      1278
           5       1.00      1.00      1.00      4778
           6       1.00      1.00      1.00      1263
           7       0.99      1.00      0.99      3498
           8       1.00      1.00      1.00       900

    accuracy                           1.00     40638
   macro avg       1.00      1.00      1.00     40638
weighted avg       1.00      1.00      1.00     40638

Accuracy Score: 0.9988926620404548
Accuracy by each class: [0.999 1.    0.997 0.99  1.    1.    1.    0.999 1.   ]
Average accuracy 0.9983053276323479
Cohenâ€™s kappa score:  0.998532689094266
Using numpy backend.
Using TensorFlow backend.
